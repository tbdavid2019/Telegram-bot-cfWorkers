import { getFileLink } from '../telegram/telegram.js';
import { ENV } from '../config/env.js';

/**
 * ASR (èªéŸ³è½‰æ–‡å­—) é…ç½® - å¤šä¾›æ‡‰å•†æ”¯æ´
 */
function getASRConfig() {
    const config = {
        apiKey: ENV.USER_CONFIG.ASR_API_KEY || ENV.USER_CONFIG.GROQ_API_KEY || ENV.USER_CONFIG.OPENAI_API_KEY[0],
        apiBase: ENV.USER_CONFIG.ASR_API_BASE || 'https://api.groq.com/openai/v1',
        model: ENV.USER_CONFIG.ASR_MODEL || 'whisper-large-v3',
        language: ENV.USER_CONFIG.ASR_LANGUAGE || 'zh'
    };

    console.log('[Voice] ASR Config:', {
        apiBase: config.apiBase,
        model: config.model,
        language: config.language
    });

    // èª¿è©¦: æª¢æŸ¥ API key ä¾†æºå’Œå…§å®¹
    console.log('[Voice] API Key Debug:', {
        ASR_API_KEY_value: ENV.USER_CONFIG.ASR_API_KEY,
        GROQ_API_KEY_value: ENV.USER_CONFIG.GROQ_API_KEY,
        OPENAI_API_KEY_value: ENV.USER_CONFIG.OPENAI_API_KEY,
        hasASR: !!ENV.USER_CONFIG.ASR_API_KEY,
        hasGROQ: !!ENV.USER_CONFIG.GROQ_API_KEY,
        hasOpenAI: !!ENV.USER_CONFIG.OPENAI_API_KEY,
        finalKeyLength: config.apiKey?.length,
        finalKeyPrefix: config.apiKey?.substring(0, 20),
        finalKeySuffix: config.apiKey?.substring(config.apiKey?.length - 10)
    });

    return config;
}

/**
 * èªéŸ³è½‰æ–‡å­— (æ”¯æ´ Groq / OpenAI ç­‰ OpenAI ç›¸å®¹ API)
 */
export async function transcribeVoiceMessage(fileUrl) {
    const config = getASRConfig();

    // ä¸‹è¼‰éŸ³è¨Š
    const audioResponse = await fetch(fileUrl);
    if (!audioResponse.ok) {
        throw new Error(`Failed to download audio: ${audioResponse.status}`);
    }
    const audioBlob = await audioResponse.blob();

    console.log('[Voice] Audio downloaded:', {
        size: audioBlob.size,
        type: audioBlob.type
    });

    // æº–å‚™ FormData (OpenAI API ç›¸å®¹æ ¼å¼)
    const formData = new FormData();
    formData.append('file', audioBlob, 'voice.ogg');
    formData.append('model', config.model);
    formData.append('language', config.language);
    formData.append('temperature', '0');
    formData.append('response_format', 'json');

    // å‘¼å« ASR API
    const endpoint = `${config.apiBase}/audio/transcriptions`;
    const response = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${config.apiKey}` },
        body: formData
    });

    if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`ASR API error (${response.status}): ${errorText}`);
    }

    const result = await response.json();
    return result.text || '';
}

/**
 * è™•ç†èªéŸ³è¨Šæ¯çš„ä¸­ä»‹å±¤
 */
export async function msgHandleVoiceMessage(message, context) {
    if (!message.voice) return null;
    if (ENV.USER_CONFIG.ENABLE_VOICE_TRANSCRIPTION === false) return null;

    try {
        console.log('[Voice] Processing voice message', {
            fileId: message.voice.file_id,
            duration: message.voice.duration,
            fileSize: message.voice.file_size
        });

        // é¡¯ç¤ºè™•ç†ä¸­ç‹€æ…‹
        await fetch(
            `https://api.telegram.org/bot${context.SHARE_CONTEXT.currentBotToken}/sendChatAction`,
            {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    chat_id: context.CURRENT_CHAT_CONTEXT.chat_id,
                    action: 'typing'
                })
            }
        );

        // å–å¾—éŸ³è¨Š URL
        const fileUrl = await getFileLink(
            message.voice.file_id,
            context.SHARE_CONTEXT.currentBotToken
        );

        if (!fileUrl) {
            throw new Error('Failed to get voice file URL');
        }

        // è½‰éŒ„èªéŸ³
        const startTime = Date.now();
        const transcribedText = await transcribeVoiceMessage(fileUrl);
        const processingTime = Date.now() - startTime;

        console.log('[Voice] Transcription completed', {
            textLength: transcribedText.length,
            processingTime: `${processingTime}ms`
        });

        if (!transcribedText.trim()) {
            throw new Error('Empty transcription');
        }

        // è¨­ç‚ºè¨Šæ¯æ–‡å­—,è®“ LLM è™•ç†
        message.text = transcribedText;

        // å¯é¸: é¡¯ç¤ºè½‰éŒ„çµæœ
        if (ENV.USER_CONFIG.SHOW_TRANSCRIPTION === true) {
            const { sendMessageToTelegramWithContext } = await import('../telegram/telegram.js');
            await sendMessageToTelegramWithContext(context)(
                `ğŸ¤ ${transcribedText}`
            );
        }

        return null; // ç¹¼çºŒåŸ·è¡Œ LLM è™•ç†

    } catch (error) {
        console.error('[Voice] Error:', error);
        console.error('[Voice] Error stack:', error.stack);
        const { sendMessageToTelegramWithContext } = await import('../telegram/telegram.js');

        // å‹å–„çš„éŒ¯èª¤è¨Šæ¯
        let errorMessage = 'âŒ èªéŸ³è™•ç†å¤±æ•—';
        if (error.message.includes('quota') || error.message.includes('limit')) {
            errorMessage = 'âŒ èªéŸ³è½‰éŒ„é¡åº¦å·²ç”¨ç›¡,è«‹ç¨å¾Œå†è©¦æˆ–ä½¿ç”¨æ–‡å­—è¼¸å…¥';
        } else if (error.message.includes('format')) {
            errorMessage = 'âŒ ä¸æ”¯æ´çš„éŸ³è¨Šæ ¼å¼';
        } else {
            // åœ¨é–‹ç™¼æ¨¡å¼ä¸‹é¡¯ç¤ºè©³ç´°éŒ¯èª¤
            if (ENV.DEBUG_MODE === 'true') {
                errorMessage = `âŒ èªéŸ³è™•ç†å¤±æ•—: ${error.message}`;
            } else {
                errorMessage = `âŒ èªéŸ³è™•ç†å¤±æ•—,è«‹ä½¿ç”¨æ–‡å­—è¼¸å…¥`;
            }
        }

        return sendMessageToTelegramWithContext(context)(errorMessage);
    }
}
