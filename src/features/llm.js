/**
 * LLM åˆ‡æ›æŒ‡ä»¤æ¨¡çµ„
 * æ”¯æ´åœ¨å¤šå€‹ OpenAI API ç›¸å®¹æœå‹™ä¹‹é–“åˆ‡æ›
 */

import { sendMessageToTelegramWithContext } from '../telegram/telegram.js';
import { DATABASE } from '../config/env.js';
import { getAllLLMProfiles, getCurrentProfileName, getActiveLLMProfile } from '../agent/agents.js';

/**
 * æ¸…ç†ä½¿ç”¨è€…é…ç½®ï¼ˆç§»é™¤ç©ºå€¼ï¼‰
 */
function trimUserConfig(userConfig) {
  const config = { ...userConfig };
  for (const key in config) {
    if (config[key] === null || config[key] === undefined || config[key] === "") {
      delete config[key];
    }
  }
  return config;
}

/**
 * /llmchange [profile] [model]
 * 
 * ä½¿ç”¨ç¯„ä¾‹ï¼š
 *   /llmchange              â†’ åˆ—å‡ºæ‰€æœ‰å¯ç”¨ profiles å’Œç›®å‰è¨­å®š
 *   /llmchange groq         â†’ åˆ‡æ›åˆ° Groqï¼ˆä½¿ç”¨è©² profile é è¨­çš„ modelï¼‰
 *   /llmchange openai gpt-4-turbo â†’ åˆ‡æ›åˆ° OpenAI ä¸¦æŒ‡å®š model
 *   /llmchange groq mixtral-8x7b-32768 â†’ åˆ‡æ›åˆ° Groq ä¸¦è¦†è“‹ model
 */
export async function commandLLMChange(message, command, subcommand, context) {
  const profiles = getAllLLMProfiles(context);
  const profileNames = Object.keys(profiles);
  
  // å¦‚æœæ²’æœ‰åƒæ•¸ï¼Œé¡¯ç¤ºç›®å‰è¨­å®šå’Œå¯ç”¨é¸é …
  if (!subcommand || subcommand.trim() === "") {
    return showLLMStatus(context, profiles, profileNames);
  }
  
  // è§£æåƒæ•¸
  const args = subcommand.trim().split(/\s+/);
  const targetProfile = args[0].toLowerCase();
  const targetModel = args[1] || null;
  
  // æª¢æŸ¥ profile æ˜¯å¦å­˜åœ¨
  if (!profileNames.includes(targetProfile)) {
    let msg = `âŒ æ‰¾ä¸åˆ° Profile: \`${targetProfile}\`\n\n`;
    msg += `å¯ç”¨çš„ Profiles:\n`;
    for (const name of profileNames) {
      const profile = profiles[name];
      msg += `â€¢ \`${name}\` - ${profile.name || name}\n`;
    }
    return sendMessageToTelegramWithContext(context)(msg);
  }
  
  try {
    // æ›´æ–°ä½¿ç”¨è€…é…ç½®
    context.USER_CONFIG.CURRENT_LLM_PROFILE = targetProfile;
    context.USER_CONFIG.DEFINE_KEYS = context.USER_CONFIG.DEFINE_KEYS || [];
    
    if (!context.USER_CONFIG.DEFINE_KEYS.includes("CURRENT_LLM_PROFILE")) {
      context.USER_CONFIG.DEFINE_KEYS.push("CURRENT_LLM_PROFILE");
    }
    
    // å¦‚æœæœ‰æŒ‡å®š modelï¼Œå‰‡è¦†è“‹
    if (targetModel) {
      context.USER_CONFIG.CURRENT_LLM_MODEL = targetModel;
      if (!context.USER_CONFIG.DEFINE_KEYS.includes("CURRENT_LLM_MODEL")) {
        context.USER_CONFIG.DEFINE_KEYS.push("CURRENT_LLM_MODEL");
      }
    } else {
      // æ¸…é™¤ä¹‹å‰çš„ model è¦†è“‹
      context.USER_CONFIG.CURRENT_LLM_MODEL = null;
      context.USER_CONFIG.DEFINE_KEYS = context.USER_CONFIG.DEFINE_KEYS.filter(k => k !== "CURRENT_LLM_MODEL");
    }
    
    // è¨­å®š AI_PROVIDER ç‚º openaiï¼ˆä½¿ç”¨ OpenAI ç›¸å®¹æ¨¡å¼ï¼‰
    context.USER_CONFIG.AI_PROVIDER = "openai";
    if (!context.USER_CONFIG.DEFINE_KEYS.includes("AI_PROVIDER")) {
      context.USER_CONFIG.DEFINE_KEYS.push("AI_PROVIDER");
    }
    
    // å„²å­˜åˆ° DATABASE
    await DATABASE.put(
      context.SHARE_CONTEXT.configStoreKey,
      JSON.stringify(trimUserConfig(context.USER_CONFIG))
    );
    
    // å–å¾—ç›®å‰ä½¿ç”¨çš„ model
    const profile = profiles[targetProfile];
    const currentModel = targetModel || profile.model || "æœªè¨­å®š";
    
    let msg = `âœ… å·²åˆ‡æ›åˆ° \`${targetProfile}\`\n`;
    msg += `ğŸ“¦ æ¨¡å‹: \`${currentModel}\``;
    
    if (targetModel && profile.model && targetModel !== profile.model) {
      msg += ` (è¦†è“‹é è¨­: ${profile.model})`;
    }
    
    return sendMessageToTelegramWithContext(context)(msg);
    
  } catch (e) {
    return sendMessageToTelegramWithContext(context)(`âŒ éŒ¯èª¤: ${e.message}`);
  }
}

/**
 * é¡¯ç¤ºç›®å‰ LLM ç‹€æ…‹å’Œå¯ç”¨é¸é …
 */
async function showLLMStatus(context, profiles, profileNames) {
  const currentProfileName = getCurrentProfileName(context);
  const currentProfile = getActiveLLMProfile(context);
  const currentModel = context.USER_CONFIG.CURRENT_LLM_MODEL 
                    || (currentProfile ? currentProfile.model : null)
                    || context.USER_CONFIG.OPENAI_CHAT_MODEL
                    || "æœªè¨­å®š";
  
  let msg = `ğŸ¤– *LLM è¨­å®š*\n`;
  msg += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n`;
  
  if (currentProfileName && currentProfile) {
    msg += `ğŸ“ ç›®å‰ä½¿ç”¨: \`${currentProfileName}\`\n`;
    msg += `ğŸ“¦ æ¨¡å‹: \`${currentModel}\`\n`;
    if (context.USER_CONFIG.CURRENT_LLM_MODEL) {
      msg += `âš¡ (å·²è¦†è“‹é è¨­æ¨¡å‹)\n`;
    }
  } else if (context.USER_CONFIG.AI_PROVIDER === "gemini") {
    msg += `ğŸ“ ç›®å‰ä½¿ç”¨: \`gemini\` (ç¨ç«‹æ¨¡å¼)\n`;
    msg += `ğŸ“¦ æ¨¡å‹: \`${context.USER_CONFIG.GOOGLE_COMPLETIONS_MODEL || "æœªè¨­å®š"}\`\n`;
  } else if (context.USER_CONFIG.OPENAI_API_KEY?.length > 0) {
    msg += `ğŸ“ ç›®å‰ä½¿ç”¨: é è¨­ OpenAI\n`;
    msg += `ğŸ“¦ æ¨¡å‹: \`${context.USER_CONFIG.OPENAI_CHAT_MODEL || "æœªè¨­å®š"}\`\n`;
  } else {
    msg += `âš ï¸ å°šæœªè¨­å®š LLM\n`;
  }
  
  msg += `\n`;
  
  if (profileNames.length > 0) {
    msg += `*å¯ç”¨çš„ Profiles:*\n`;
    for (const name of profileNames) {
      const profile = profiles[name];
      const isActive = name === currentProfileName;
      const prefix = isActive ? "âœ“" : "â€¢";
      msg += `${prefix} \`${name}\` - ${profile.name || name}`;
      if (profile.model) {
        msg += ` (${profile.model})`;
      }
      msg += `\n`;
    }
  } else {
    msg += `âš ï¸ å°šæœªè¨­å®šä»»ä½• LLM Profile\n`;
    msg += `è«‹åœ¨ç’°å¢ƒè®Šæ•¸ä¸­è¨­å®š \`LLM\\_PROFILES\`\n`;
  }
  
  msg += `\n`;
  msg += `*ä½¿ç”¨æ–¹å¼:*\n`;
  msg += `/llmchange <profile> [model]\n`;
  msg += `ä¾‹: \`/llmchange groq\`\n`;
  msg += `ä¾‹: \`/llmchange openai gpt-4-turbo\`\n`;
  
  context.CURRENT_CHAT_CONTEXT.parse_mode = "Markdown";
  return sendMessageToTelegramWithContext(context)(msg);
}
